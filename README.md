# docker-ecommerce

## Business Case

To deploy simple viable batch pipelines entirely on Docker with Cassandra, Redis and MySQL databases
 
### Focus

I successfully engineered batch data processing pipelines entirely on Docker. I ingested, processed and visualized the data in the database to validate successful deployment.

(I finished the programming part of my project. I'm now working on GitHub documentation as well as sharing my learnings and Apache Spark (pyspark) through my [blog](https://bit.ly/PrakashDontarajuMedium))

## Data

Company name, Kaggle as source, link. Data does not reflect real life data. It's well structured, formatted and hence requires minimal cleaning. Focus was on constructing the pipeline.

### Properties of data

Explanation of columns, Repetitions, Transformations, Duration of data, creating a sample.

## Batch Pipelines Implementation

Batch data processing, pyspark for batch data processing, business advantage of docker implementation, docker vs kubernetes, thought process in selecting databases, challenges during implementation, visualizing data in the database

## Deployment

Instructions to implement the pipelines with the files readily available

## Next Steps

Use different databases in the same pipeline for different purposes using same data, scheduling these jobs on docker with airflow

## Connect With Me On
**Prakash Dontaraju** [LinkedIn](https://bit.ly/PrakashDontarajuLinkedIn) [Medium](https://bit.ly/PrakashDontarajuMedium)