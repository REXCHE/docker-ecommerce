# docker-ecommerce

## Business Case

Our customers (subscribers) seek help to build skills to deploy simple and viable batch pipelines entirely on Docker involving the following relational and NoSQL databases:
* Cassandra
* MySQL
* Redis

(I finished the successful implementation of this project. I'm now working on documentation in the sections that follow as well as sharing my learnings and Apache Spark (pyspark) expertise through my [blog.](https://medium.com/@wittygrit))
 
### Focus

I successfully engineered batch data processing pipelines entirely on Docker. I ingested, processed and visualized the data in the database to validate successful deployment.

## Data

Include e-commerce details from Kaggle with link. Data is well structured, formatted and hence requires minimal cleaning. T chose this because my focus was on successfully constructing the pipeline and not cleaning data. I still do a little pre-processing of data. Real life data requires a lot of pre-processing.

### Properties of data

Provide explanation of columns, Repetitions, Transformations, Duration of data, creating a data sample.

## Batch Pipelines Implementation

Batch data processing, pyspark for batch data processing, business advantage of docker implementation, docker & kubernetes, thought process in selecting databases, challenges during implementation, visualizing data in the database

## Deployment

Detail: Instructions to implement the pipelines with the files readily available

## Next Steps

Use different databases in the same pipeline for different purposes using same data, scheduling these jobs on docker with airflow

## Connect With Me
**Prakash Dontaraju** [LinkedIn](https://www.linkedin.com/in/prakashdontaraju) [Twitter](https://twitter.com/WittyGrit) [Medium](https://medium.com/@wittygrit)
